{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9850633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load datasets\n",
    "wind_data = pd.read_csv('wind_data.csv')\n",
    "avg_ps = pd.read_csv('Wind_Factor_Daily_AVG_PS.csv')\n",
    "avg_t2m = pd.read_csv('Wind_Factor_Daily_AVG_T2M.csv')\n",
    "avg_wd50m = pd.read_csv('Wind_Factor_Daily_AVG_WD50M.csv')\n",
    "avg_ws50m = pd.read_csv('Wind_Factor_Daily_AVG_WS50M.csv')\n",
    "\n",
    "# Preprocessing\n",
    "wind_data = wind_data.rename(columns={'Trading_date': 'DATE'})\n",
    "for df in [wind_data, avg_ps, avg_t2m, avg_wd50m, avg_ws50m]:\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "\n",
    "# Merge datasets on DATE\n",
    "data_df = wind_data.merge(avg_ps, on=\"DATE\")                    .merge(avg_t2m, on=\"DATE\")                    .merge(avg_wd50m, on=\"DATE\")                    .merge(avg_ws50m, on=\"DATE\")\n",
    "\n",
    "# Drop missing and filter Wind data\n",
    "data_df = data_df[data_df[\"Fuel_Code\"] == \"Wind\"].drop(columns=[\"Fuel_Code\"])\n",
    "data_df.set_index(\"DATE\", inplace=True)\n",
    "data_df.dropna(inplace=True)\n",
    "\n",
    "# Correlation analysis\n",
    "corr = data_df.corr()\n",
    "top2 = corr[\"Total_TP\"].abs().sort_values(ascending=False)[1:3].index.tolist()\n",
    "print(\"Top 2 correlated variables:\", top2)\n",
    "\n",
    "# Define features and target\n",
    "X = data_df[top2].values\n",
    "y = data_df[\"Total_TP\"].values\n",
    "\n",
    "# Scale features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X_scaled[:split_idx], X_scaled[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# ANN Model\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(X_train.shape[1],)),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(32),\n",
    "    LeakyReLU(),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.2,\n",
    "                    epochs=100, batch_size=32, callbacks=[early_stop], verbose=0)\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(X_test).flatten()\n",
    "\n",
    "# Evaluation\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "\n",
    "print(f\"✅ ANN MAE: {mae:,.2f}\")\n",
    "print(f\"✅ ANN RMSE: {rmse:,.2f}\")\n",
    "print(f\"✅ ANN MAPE: {mape:.2f}%\")\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(y_test, label=\"Actual\")\n",
    "plt.plot(predictions, label=\"Predicted\", linestyle=\"--\")\n",
    "plt.title(\"ANN: Actual vs Predicted Wind Generation\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Generation\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
